<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-10-31T15:26:31+01:00</updated><id>http://localhost:4000/</id><title type="html">Swapneel Mehta</title><subtitle>Swapneel's Blog</subtitle><entry><title type="html">Machine Learning Summer Schools</title><link href="http://localhost:4000/machine-learning-summer-schools" rel="alternate" type="text/html" title="Machine Learning Summer Schools" /><published>2018-10-16T00:00:00+02:00</published><updated>2018-10-16T00:00:00+02:00</updated><id>http://localhost:4000/machine-learning-summer-schools</id><content type="html" xml:base="http://localhost:4000/machine-learning-summer-schools">&lt;h2 id=&quot;machine-learning-summer-schools&quot;&gt;Machine Learning Summer Schools&lt;/h2&gt;

&lt;p&gt;This post is the first in a series of posts highlighting my attempt(s) to prepare myself to undertake research and for graduate school. It will include a year in review, learnings from working at CERN, and some technical posts about the kind of work I do.&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;I’m a recent graduate of Computer Engineering working at the European Organisation for Nuclear Research (CERN). I got into a “US top-15” school for pursuing a Masters in Computer Science starting 2018 but chose to work as a Technical Student for a year instead. My goal in spending this year at CERN is to to gain more perspective and better understand my interests before diving straight into graduate school. As I worked on &lt;a href=&quot;https://github.com/DL4Jets/DeepJetCore&quot;&gt;projects&lt;/a&gt; at the CMS Experiment, I really developed a strong liking for problems we face in high-energy physics. This series of posts will serve as a reflection of the people I have met and experiences I have shared over the past summer.&lt;/p&gt;

&lt;h3 id=&quot;applying-to-summer-schools&quot;&gt;Applying to Summer Schools&lt;/h3&gt;

&lt;p&gt;The year started on a mixed note;  I was excited about working at CERN, but also wondering what directions to take in order to prepare for graduate studies. My aim is to learn by doing and make the most of opportunities that come along. So I decided to figure out how to improve my knowledge of machine learning that was essentially self-taught—taking online courses and working on a project aiding the deployment Tensorflow models in production on the CMS Software Environment. I spent two weeks researching and applying to machine learning summer schools with my supervisor (and former supervisor) supporting me with reference letters wherever necessary.&lt;/p&gt;

&lt;p&gt;The schools had some really cool speakers lined up which I thought would make for a great introduction to subjects like gaussian processes, natural language processing, causal inference, probabilistic methods, bayesian non-parametrics, and optimisation. The application process for the schools was fairly straightforward (often doing away with the reference letter) and encouraged students to present posters of their ongoing/completed projects. I ended up visiting two schools - Machine Learning in High-energy Physics Summer School (Oxford, UK) and Machine Learning Summer School (Madrid, Spain), apart from the Deep Learning Indaba (Stellenbosch, SA). My poster on our work (DeepJet) was presented at MLSS and the Indaba.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: I learnt later how presenting posters forms a critical part of the experience; it fosters discussions on a plethora of interconnected domains promoting quick and reliable knowledge transfer. As Jeff Dean said in a talk at the Deep Learning Indaba, “If I had a choice between reading one research paper in great depth or just skimming through ten papers, I would choose the latter because that gives me a broader idea of the problem space that I can then build upon.” Poster presentations accomplish pretty much the same goal and in addition foster collaboration and interest in relevant work by others you may not otherwise hear of.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: I also learnt later how lucky I was to have qualified for these events that are otherwise primarily targeted at an audience of Ph.D. students (except for the Deep Learning Indaba). This gave me an invaluable set of opportunities to connect with researchers and graduate students who were perfectly equipped to offer &lt;strong&gt;relevant&lt;/strong&gt; advice to me (a lot of people can offer advice, but very little is often relevant).&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h2&gt;

&lt;p&gt;Here’s a brief outline of each of these events along with what I learnt from each of them. In this post, I’ve focused on the &lt;a href=&quot;https://indico.cern.ch/event/687473&quot;&gt;Fourth Machine Learning in High-energy Physics Summer School&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;mlhep-2018&quot;&gt;MLHEP 2018:&lt;/h3&gt;
&lt;p&gt;The Machine Learning in High-energy Physics Summer School was organised by researchers from Yandex, Skoltech, and HSE at Oxford University in the UK. It is an event targeted at Ph.D. students and Professors in Physics seeking a foothold in machine learning to find applications to their respective problem statements. However, given that I was working on a project along similar lines, it served as a pretty good primer for me.&lt;/p&gt;

&lt;h5 id=&quot;school-highlights&quot;&gt;School Highlights&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;The school began with two tracks—one slightly more advanced introduction and another for beginners to programming and data science.&lt;/li&gt;
  &lt;li&gt;The lectures adhered to a (really useful) hands-on format where each talk was followed by a practical coding session teaching the practical uses of each model.&lt;/li&gt;
  &lt;li&gt;The &lt;a href=&quot;https://github.com/yandexdataschool/mlhep2018&quot;&gt;MLHEP Starter code&lt;/a&gt; was really well documented and overall quite thorough in its treatment of the subject. It should serve as a useful reference even for those who have not attended the event.&lt;/li&gt;
  &lt;li&gt;There was a set of invited lectures (one per day) that was truly the highlight of each day. It made me wonder how they shortlisted speakers but whatever the process was, it clearly worked. From an introduction to Quantum Physics and Deep Learning to NVidia’s use of AI, to Advertisements on Oracle Data Cloud, and a detailed architectural breakdown of Google’s newly introduced Tensor Processing Unit - these lectures did not disappoint! The slides for each of these lectures has been kindly &lt;a href=&quot;https://github.com/yandexdataschool/mlhep2018&quot;&gt;made available&lt;/a&gt; by the organisers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;The Codalab Challenge&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Amidst a packed (read 7:30 am - 7 pm) schedule that prevented me from visiting this popular vegan joint (sadly, it shut by 5 pm daily) we had yet another activity - a multi-phase &lt;a href=&quot;https://competitions.codalab.org/competitions/19818&quot;&gt;Codalab Challenge&lt;/a&gt; on the Semantic Segmentation of LArTPC tracks! Phase 1 was now open to us and the rest would follow soon after.&lt;/li&gt;
  &lt;li&gt;If you don’t understand much about the title, don’t be disappointed. I didn’t either. In fact, I had absolutely no clue what this was. But I did know that we had free GPU Credit and some &lt;a href=&quot;https://github.com/yandexdataschool/mlhep2018-starterkit&quot;&gt;starter code&lt;/a&gt;, and when someone is so kind as to give you a free GPU and some machine learning models, it is only natural for your overfitting instincts to kick into overdrive. So overfitting aside, that’s exactly what I did.&lt;/li&gt;
  &lt;li&gt;My first four attempts gave me exactly zero accuracy. I had no idea what I was doing wrong. After 14 hours of training (I woke up intermittently through the night to check up on the model) I realized I was not preprocessing the data correctly. Long story short, after a series of modifications to my code, I arrived upon a seriously crappy model and placed almost last on the leaderboard.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;That was probably my breaking point.&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Now there were two undergrads at the school who didn’t really participate in the challenge (to my knowledge, and based on the leaderboard). The rest of the thirty-ish people were Physics Ph.D. Students. They understood exactly what a &lt;a href=&quot;https://en.wikipedia.org/wiki/Time_projection_chamber&quot;&gt;Liquid Argon Time Projection Chamber&lt;/a&gt; was in addition to having the same starter code and with a reasonably good understanding of machine learning as well. Then there was me - the third undergrad with almost entirely self-taught knowledge of machine learning (I’ll write another post sometime about my opinion on the Indian Education System) and barely any understanding of the properties of the track data. Did I really expect myself to miraculously arrive at optimal hyperparameters for this problem given that I was already drained after 12 hours of attending the school daily?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Then, I binged on a box of Pringles and reevaluated matters&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I was an undergrad among 2nd and 3rd year Ph.D. students (also some Professors) and I still managed to not only get in but also successfully understand most of the topics taught in the school.&lt;/li&gt;
  &lt;li&gt;The very fact that I had a submission placed me in the top-30% of the school (many people decided against participating due to various issues including the time constraints and a limited understanding of the starter code).&lt;/li&gt;
  &lt;li&gt;I did finally start understanding what LArTPC was about, after watching some introductory lectures. It wasn’t that complicated. And the history of the problem was very cool (I like reading about the story behind things).&lt;/li&gt;
  &lt;li&gt;I used the more complicated model - the Message-passing Neural Network instead of the Convolutional Neural Network simply because I wanted to ‘try something new.’ I managed my model fairly well by tweaking the learning rate, playing around with dropout to prevent overfitting, switching around optimizers, and adjusting the number of training epochs. The accuracy (to my recollection) was 80-something percent.&lt;/li&gt;
  &lt;li&gt;Given that it was my first Kaggle-like challenge, this was a pretty great outcome. Giving up now would be a very silly idea. Either way, there was only a day more left. Instead, why not try to push harder for a day without any expectation and see what I get.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;So I did.&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I landed up 4th on the Phase 1 Leaderboard for the challenge with an accuracy of 90-something percent. This wasn’t the miracle win I expected (blame Hollywood for setting my expectations high) but it was undoubtedly a decent result for a first-timer given the aforementioned constraints.&lt;/li&gt;
  &lt;li&gt;The next morning, the CodaLab Challenge winners were asked to present their models. &lt;a href=&quot;https://github.com/yandexdataschool/mlhep2018/blob/master/day6-Sun/AlexHeld-20180812_MLHEP2018.pdf&quot;&gt;Alex&lt;/a&gt;, who stood first on the leaderboard, came up to explain his entry.&lt;/li&gt;
  &lt;li&gt;As I listened to Alex talk about how he visualized the data (used the CNN for visualizing the features? not clear on this) and tweaked the learning rate and a lot of jargon (but in the nice sense), I was very impressed with the work. Having nothing else to focus on as they announced the next winner, I started planning my journey back to Heathrow from Oxford - I didn’t want to miss my flight.&lt;/li&gt;
  &lt;li&gt;A friend sitting next to me elbows me as he points to the leaderboard. “Isn’t that you?” 
“What?”
“&lt;code class=&quot;highlighter-rouge&quot;&gt;smehta&lt;/code&gt;, that’s your username right?”
“Oh, right. Well, shit.”&lt;/li&gt;
  &lt;li&gt;Mother of God, I stood second. How? Well, you see the challenge had multiple phases, and they simply used the test data from the second phase (only slightly advanced from Phase 1) to evaluate the models. This resulted in some models not performing as well - surprisingly enough, mine did. They had told us this before, and I remember I had tweaked my training and preprocessing to accommodate for a better score overall, but I was so busy with training afterwards that I forgot they would consider the results of Phase 2.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;“Can the user &lt;code class=&quot;highlighter-rouge&quot;&gt;smehta&lt;/code&gt; please come up and explain their approach?”&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I knew I wasn’t going to follow up Alex’s presentation with something really technical so I decided to do the easy thing - tell them exactly how I did it.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;“I’ve never used a Message-passing Neural Network and I wanted to see how it works so that was my main motivation in participating in this challenge. My first few tries failed which was when I updated my preprocessing pipeline. The core principle I used to tweak my training parameters was basically what Andrew Ng said in Coursera Machine Learning, Week 4 - ‘If you are approaching a minima you need to adjust your number of training steps and learning rate such that you neither overshoot it nor converge too slow.’”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;That, ladies and gentlemen, is what I call machine learning (sarcasm? maybe).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Stay tuned for more posts about experiences from the two other events that I had the privilege to attend this year - Machine Learning Summer School (Madrid), and the Deep Learning Indaba (South Africa).&lt;/strong&gt;&lt;/p&gt;</content><author><name>Swapneel Mehta</name></author><category term="summer-school" /><summary type="html">Machine Learning Summer Schools</summary></entry><entry><title type="html">Writing a Statement of Purpose</title><link href="http://localhost:4000/writing-a-statement-of-purpose" rel="alternate" type="text/html" title="Writing a Statement of Purpose" /><published>2018-10-16T00:00:00+02:00</published><updated>2018-10-16T00:00:00+02:00</updated><id>http://localhost:4000/writing-a-statement-of-purpose</id><content type="html" xml:base="http://localhost:4000/writing-a-statement-of-purpose">&lt;h3 id=&quot;the-disclaimer&quot;&gt;The Disclaimer&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;This comes first because people often tend to ignore this very relevant section.&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;There is &lt;em&gt;obviously&lt;/em&gt; no single way to achieve a successful outcome for your application to graduate school and this post comprises mainly of opinions that I hold based on no evidence other than a product of my personal experience with the process (which is limited, to say the least). All I’m trying to do by writing about this is to give you some perspective to enable you to think for yourself before you embark on the arduous process of applying to grad school. Goodluck!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Needless to say, please refrain from plagiarising the content. You know how badly a few lifted (and/or uncited) lines could mess up your application (and academic career), right?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Look at this set of personal statements, instead, as the quality of essays that your competition writes (these are for a mix of Ph.D. and Masters programs) and use it as positive reinforcement to ‘up your game,’ so to speak.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;While applying to grad school, please don’t make amateur-ish mistakes for your essays. It’s a really cliched piece of advice when people say “you should tell them a story.” Don’t get me wrong, you can. But you don’t have to.&lt;/p&gt;

&lt;p&gt;Please read this if you haven’t done so already: &lt;a href=&quot;http://www.cs.cmu.edu/~pavlo/blog/2015/10/how-to-write-a-bad-statement-for-a-computer-science-phd-admissions-application.html&quot;&gt;How to Write a Bad Statement for a Computer Science Ph.D. Admissions Application, Andy Pavlo (CMU)&lt;/a&gt; (it is Ph.D. specific, but you can extrapolate to Masters applications).&lt;/p&gt;

&lt;p&gt;That said, admissions are very variable and top schools almost always look favourably upon relevant national and international awards, and publications at top-tier venues especially when they filter applicants for competitive programs like CS (AI/ML).&lt;/p&gt;

&lt;p&gt;Weaving stories, as stated before, may make or break your case depending on who reviews it. Ultimately I believe it’s a math.random() process because there is a human on the other end, and human intelligence - unlike many manifestations of artificial intelligence - is highly unpredictable. I wanted to share some links for reading before you guys start writing (since we’re only a month out from the earliest deadlines in November, hopefully you’ve already started writing a draft).&lt;/p&gt;

&lt;h3 id=&quot;general-grad-school-advice&quot;&gt;General Grad School Advice&lt;/h3&gt;

&lt;h4 id=&quot;statement-of-purpose&quot;&gt;Statement of Purpose:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://cseweb.ucsd.edu/~gary/Advice.html&quot;&gt;Very useful Meta Page of Links and Advice by Prof. Gary Cottrell&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://pgbovine.net/grad-school-applications-summary.htm&quot;&gt;Ph.D. specific advice from Prof. Philip Guo’s Blog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cl.cam.ac.uk/~sbh11/phd_apply.html&quot;&gt;Dr. Sean Holden’s advice for applying to do a Ph.D. in Machine Learning (University of Cambridge)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www-personal.umich.edu/~danhorn/graduate.html&quot;&gt;Grad School Advice by Prof. Dan Horn&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://forum.thegradcafe.com/topic/48905-some-advice-on-writing-an-sop/&quot;&gt;SoP Advice from the GradCafe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;letters-of-recommendation&quot;&gt;Letters of Recommendation:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://homes.cs.washington.edu/~mernst/advice/request-recommendation.html&quot;&gt;How to request a letter of recommendation, Michael Ernst (UWash)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://homes.cs.washington.edu/~mernst/advice/write-recommendation.html&quot;&gt;How to write a letter of recommendation, Michael Ernst (UWash)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cs.brown.edu/~sk/Memos/Grad-School-Recos/&quot;&gt;Advice to Letter Writers by Prof. Shriram Krishnamurthi (Brown Univ.)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;some-examples-of-sops&quot;&gt;Some examples of SoPs:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.cmu.edu/~jlacomis/assets/statement/personal-statement-cmu.pdf&quot;&gt;Jeremy Lacomis’ Statement of Purpose for a Ph.D. at Carnegie Mellon University focusing on Software Engineering focusing on Programming Languages&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/jeanqasaur/academic-application-materials/blob/master/phd-application-2007/personal_statement.pdf&quot;&gt;Jean Yang’s Statement of Purpose for a Ph.D. in Computer Science&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://pgbovine.net/PhD-applications/Philip_Guo-Stanford-PhD-app-statement.pdf&quot;&gt;Philip Guo’s Statement of Purpose for a Masters in Computer Science at Stanford University&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://seankross.com/notes/grad-school-essays/&quot;&gt;Sean Kross’ Set of Statements for Graduate School - focusing on Information and Cognitive Science&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.andrew.cmu.edu/user/vipuls/me/sop_vipulsingh.pdf&quot;&gt;Vipul Singh’s Statement of Purpose for a Masters in Computer Science at Carnegie Mellon University&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Research Statements from professors/research scientists/Ph.D. Students often yield insight into not only their goals, but also areas of active research in general which is why I’m including some samples for candidates to read in order to ‘get a better idea of their field’ before writing their Statement of Purpose.&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.ualberta.ca/~szepesva/CV/Research%20Statement.pdf&quot;&gt;Csaba Szepesvári’s Research Statement (University of Alberta, DeepMind)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://people.eecs.berkeley.edu/~jda/docs/jda_research_statement.pdf&quot;&gt;Jacob Andreas’ Research Statement (Berkeley, MIT, Natural Language Processing)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cs.nyu.edu/~ranzato/research/research_statement_ranzato.pdf&quot;&gt;Marc’Aurelio Ranzato’s Research Statement (New York University, Machine Learning)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;web.stanford.edu/~morteza/research_statement.pdf&quot;&gt;Morteza Mardani’s Reserach Statement (Stanford, Algorithms, Applications of Machine Learning)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cs.stanford.edu/~jsteinhardt/statement.pdf&quot;&gt;Jacob Steinhardt’s Statement of Purpose (Stanford, Machine Learning)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.ics.uci.edu/~numanare/files/research_niranjan.pdf&quot;&gt;U. N. Niranjan’s Research Statement (U.C. Irvine, Machine Learning)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;my-personal-favourite---anant-bhardwaj-beng-pune-univ-ms-stanford-phd-mit&quot;&gt;My personal favourite - Anant Bhardwaj (B.Eng. Pune Univ., M.S. Stanford, Ph.D. M.I.T.):&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Mainly because this was the first (and only) Statement of Purpose I read before applying for a Masters in Computer Science right after undergrad (although I later decided not to jump into it, but work at CERN for a year instead).&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Before you read this set of statements, I’d like to explain my reasons for highlighting this one.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;It clearly depicts how an SoP evolves from a story woven around nascent experience working in tech and aimed at a short-term goal into a research statement that focuses on a specific field and hopes to achieve a long-term goal.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As an Indian B.Eng. student at Mumbai University, I could really identify with this as it was written by a fellow B.Eng. graduate from Pune University.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It’s a good example of progress and change of plans coming from a student who went on to do a Masters at Stanford and a Ph.D. at MIT and then dropped out midway to found a company called Instabase.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Another disclaimer: please do not treat this as a single representative example of how to frame your statement of purpose.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://people.csail.mit.edu/anantb/public/docs/sop/ms_admission_sop.pdf&quot;&gt;Statement of Purpose - Masters in Computer Science&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://people.csail.mit.edu/anantb/public/docs/sop/phd_admission_sop.pdf&quot;&gt;Statement of Purpose - Ph.D. in Computer Science&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;my-two-cents-on-this-subject&quot;&gt;My Two Cents on this subject:&lt;/h3&gt;

&lt;p&gt;A lot of these people and a lot of the advice you will see states that they know the exact field they wanted to work on. That is false. Nobody knows exactly what they want to to for the rest of their lives. Very few actually know the general area they want to work on. Most people have only a fair idea and as Ph.D. programs often state on their websites, that is OK. Most of your ideas will change with experience anyway.&lt;/p&gt;

&lt;p&gt;For instance, if you like X a lot but you’ve never tried doing Y, how do you know you don’t like Y and how can you say you won’t like Y more than X once you try it out. That’s understandable. However, you will see that all of these people have one thing in common - clarity. They possess a high degree of clarity in their research focus and know that there are one or two fields that they would definitely like to pursue. All they have done is explain why this is the case. And their innate clarity made the rest of the work they did fit into the theme of their ‘stories.’&lt;/p&gt;

&lt;p&gt;Essentially, what you’re trying to do in your essay is explain one or two directions that you would like to take, back your claim up with evidence (yes, material evidence - including grades, research, and/or projects) of why you would do well in those directions, and finally state what you see yourself doing once you actually get into that direction. Clarity of thoughts is way more important and the only reliable way to get that is to actually be aware of what that direction is; follow active research areas and people working in that direction, and finally, at least have some ideas of what you would do if you were given an opportunity to work there. Write confidently; you don’t necessarily need to highlight why you failed or justify any misses if you can focus on the hits. It’s not necessary that your statement of purpose would have to ‘make up for why you’re not as good as you could have been’ as opposed to ‘focus on how good you can be based on what you have already done.’&lt;/p&gt;

&lt;h3 id=&quot;further-reading-strongly-recommended-if-you-have-the-time&quot;&gt;Further Reading (strongly recommended if you have the time)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://matt.might.net/articles/how-to-apply-and-get-in-to-graduate-school-in-science-mathematics-engineering-or-computer-science/&quot;&gt;Reddit Thread on Resources for Graduate School&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;p&gt;This post has been composed by using publicly available documents shared by a fantastic set of researchers in an effort to help those that are seeking such information. I’ve simply listed them as they are, linking back to the original references.&lt;/p&gt;

&lt;p&gt;If there is any issue with this, please feel free to contact me via email and I will be happy to remove the link(s) from this post.&lt;/p&gt;</content><author><name>Swapneel Mehta</name></author><category term="grad-school" /><summary type="html">The Disclaimer</summary></entry><entry><title type="html">Coursework to Complete</title><link href="http://localhost:4000/coursework-to-complete" rel="alternate" type="text/html" title="Coursework to Complete" /><published>2017-03-24T00:00:00+01:00</published><updated>2017-03-24T00:00:00+01:00</updated><id>http://localhost:4000/coursework-to-complete</id><content type="html" xml:base="http://localhost:4000/coursework-to-complete">&lt;h2 id=&quot;an-exhaustive-list-of-course-lectures&quot;&gt;An Exhaustive List of Course Lectures&lt;/h2&gt;

&lt;p&gt;This post comprises of a list of lectures that I intend to watch at some point in order to mainly just learn more about these domains. They seem like some interesting areas to explore and some are just plain fun!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Note&lt;/code&gt;&lt;/strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;: This list is just for personal reference; you may use it if you like, but it is by no means an exhaustive list.&lt;/code&gt;  &lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;That said, I have put in a fair bit of research into comparing prerequisites and course information across MIT, Stanford and other colleges whilst compiling this list that should provide a fair overview, to an undergraduate student interested in exploring Machine Learning and Computer Vision, of the courses that relate to the applications of these practices in Genetics and Genomics (yes, they're disparate branches of Biology).&lt;/code&gt;  &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tl;dr&lt;/code&gt;&lt;/strong&gt; &lt;br /&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;It's just a list of courses that I'm interested in, oriented around ML and CV.&lt;/code&gt;  &lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;algorithms&quot;&gt;Algorithms:&lt;/h2&gt;

&lt;p&gt;6.006J - Introduction to Algorithms [UG]  &lt;em&gt;prerequisite for 6.046J&lt;/em&gt;  &lt;br /&gt; 
6.046J - Design and Analysis [UG]  &lt;em&gt;prerequisite for 6.84J&lt;/em&gt;  &lt;br /&gt; 
6.84J - Advanced Algorithms [G]  &lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;mathematics-and-statistics&quot;&gt;Mathematics and Statistics:&lt;/h2&gt;

&lt;p&gt;18.02 - &lt;strong&gt;Multivariable Calculus (II)&lt;/strong&gt; [UG]  &lt;em&gt;prerequisite for 6.041F&lt;/em&gt;  &lt;br /&gt; 
18.06 - &lt;strong&gt;Linear Algebra&lt;/strong&gt; [UG]  &lt;em&gt;prerequisite for CS229&lt;/em&gt;  &lt;br /&gt; 
18.05 - &lt;strong&gt;Introduction to Probability and Statistics&lt;/strong&gt; [UG]  &lt;em&gt;prerequisite for CS229&lt;/em&gt;  &lt;br /&gt; 
6.041F - &lt;strong&gt;Probabilistic Systems Analysis and Applied Probability&lt;/strong&gt; [UG/G]  &lt;br /&gt; 
6.262 - &lt;strong&gt;Discrete Stochastic Processes&lt;/strong&gt; [G]  &lt;em&gt;prerequisite for 10-715 (CMU)&lt;/em&gt;  &lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;machine-learning&quot;&gt;Machine Learning:&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;10-401, 10-601, 10-701, and 10-715 are all introductory courses but 10-715 and 10-701 are intended for graduate students with a strong mathematical background.&lt;/em&gt;  &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;CS229 - &lt;strong&gt;Machine Learning&lt;/strong&gt; [UG]  &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;10-701 - &lt;strong&gt;Introduction to Machine Learning&lt;/strong&gt; [UG/G]  &lt;em&gt;prerequisite for 10-702, 10-715&lt;/em&gt;  &lt;br /&gt; 
10-702 - &lt;strong&gt;Statistical Machine Learning&lt;/strong&gt; [G]  &lt;br /&gt; 
10-715 - &lt;strong&gt;Advanced Introduction to Machine Learning&lt;/strong&gt; [G]  &lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;biology&quot;&gt;Biology:&lt;/h2&gt;

&lt;p&gt;7.012 - &lt;strong&gt;Introduction to Biology&lt;/strong&gt; [UG]  &lt;em&gt;prerequisite for 7.91J, 8.591J&lt;/em&gt;  &lt;br /&gt; 
7.91J - &lt;strong&gt;Foundations of Computational and Systems Biology&lt;/strong&gt; [UG/G]  &lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;computer-vision&quot;&gt;Computer Vision:&lt;/h2&gt;

&lt;p&gt;CS231N - &lt;strong&gt;Convolutional Neural Networks for Visual Recognition&lt;/strong&gt; [UG]  &lt;br /&gt; 
CAP5415 - &lt;strong&gt;Computer Vision&lt;/strong&gt; [UG]  &lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;optional-courses&quot;&gt;Optional Courses:&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;8.591J - Systems Biology [UG/G]&lt;/em&gt;  &lt;br /&gt; 
&lt;em&gt;6.034 - Artificial Intelligence [UG]&lt;/em&gt;  &lt;br /&gt; 
&lt;em&gt;6.042J/18.062J - Mathematics for Computer Science [UG]&lt;/em&gt;  &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;18.085 - Computational Science and Engineering (I) [G]&lt;/em&gt;  &lt;br /&gt; 
&lt;em&gt;18.086 - Mathematical Methods for Engineers (II) [G]&lt;/em&gt;  &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;18.01 - Single Variable Calculus (I) [UG]&lt;/em&gt;  &lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;links&quot;&gt;Links:&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ml.cmu.edu/current-students/electives-for-ms-students.html&quot;&gt;CMU Electives for ML Students&lt;/a&gt;  &lt;br /&gt;&lt;/p&gt;</content><author><name>Swapneel Mehta</name></author><category term="getting-started" /><summary type="html">An Exhaustive List of Course Lectures</summary></entry><entry><title type="html">The Blog</title><link href="http://localhost:4000/the-blog" rel="alternate" type="text/html" title="The Blog" /><published>2017-03-21T00:00:00+01:00</published><updated>2017-03-21T00:00:00+01:00</updated><id>http://localhost:4000/the-blog</id><content type="html" xml:base="http://localhost:4000/the-blog">&lt;h3 id=&quot;why-blog&quot;&gt;Why Blog?&lt;/h3&gt;

&lt;p&gt;I like to look back on the things that I do and writing comes easily to me - it just seems like the logical thing to do. Frankly, I’m surprised it took me so long to actually (finally) build a decent-ish blog.&lt;/p&gt;

&lt;p&gt;In a line, it helps get things off my mind in a quick, efficient, indexable manner. Writing often serves as a great tool for introspection.&lt;/p&gt;

&lt;p&gt;I finally got around to putting this together after a 5-year journey spanning Wordpress, Blogger, Medium, and plain ol’ &lt;code class=&quot;highlighter-rouge&quot;&gt;.txt&lt;/code&gt; drafts of posts that are now likely to see the light of day.&lt;/p&gt;

&lt;h3 id=&quot;title&quot;&gt;Title&lt;/h3&gt;

&lt;p&gt;I am still thinking of a better title for this blog but in the meanwhile I think I’m just going to leave it as &lt;code class=&quot;highlighter-rouge&quot;&gt;The Blog&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;technical-details&quot;&gt;Technical Details&lt;/h3&gt;

&lt;p&gt;The site is powered by &lt;a href=&quot;http://jekyllrb.com&quot;&gt;Jekyll&lt;/a&gt; with the posts written in Markdown. 
I’ve used a theme called &lt;a href=&quot;https://github.com/jekyller/jasper2&quot;&gt;Jasper2&lt;/a&gt; that’s based on the default theme for a publishing platform called &lt;a href=&quot;https://www.ghost.org&quot;&gt;Ghost&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Try it out, it’s pretty neat!&lt;/p&gt;

&lt;h3 id=&quot;disclaimer&quot;&gt;Disclaimer&lt;/h3&gt;

&lt;p&gt;Word of advice to the readers - my opinions are thoughtful, but loosely held (I swear this is not motivated by the &lt;a href=&quot;https://fs.blog/principles/&quot;&gt;Farnam Street Principles&lt;/a&gt;). When I write opinion pieces, I do not see it as a permanent and unchanging stance for the simple reason that I do not believe I know everything about anything. Happy reading!&lt;/p&gt;</content><author><name>Swapneel Mehta</name></author><category term="getting-started" /><summary type="html">Why Blog?</summary></entry></feed>